namespace ltr {
/** \page TutorialMeasureLearnerScorer Measures, Learners, Scorers
    \ingroup Tutorial

\section Introduction Introduction

\tableofcontents

The key concept of LTR is Scorer. Scorer is a functor which computes
score of an object:

\dot
digraph {
rankdir=LR
margin=0.2
a [ shape="oval" label="Object" URL="\ref ltr::Object"];
b [ shape="box"  label="Scorer" URL="\ref ltr::Scorer"];
c [ shape="plaintext"  label="score"];
a -> b [label="value()"];
b -> c;
}
\enddot

Learner learn a train data to make the Scorer which aproximates
the actual labels of the objects in the train data:

\dot
digraph {
rankdir=LR
margin=0.2
a [ shape="note" label="DataSet" URL="\ref ltr::DataSet"];
b [ shape="box"  label="Learner" URL="\ref ltr::Learner"];
c [ shape="box"  label="Scorer" URL="\ref ltr::Scorer"];
a -> b [label="learn()"];
b -> c [label="make()"];
}
\enddot

One should use a Measure to check the quality of aproximation.

LTR was originally designed to solve learning to rank problem.
But actualy it can be used to solve a various problems of machine learning.
The difference is in the type of train data, usage of the result scorer
and the target metric:

Problem                     |   %Dataset |   %Scorer usage                      |    %Measure
----------------------------|------------|--------------------------------------|--------------------
Binary classification       |{Point, Pair}wise  | \f$ score < \text{or} > 0 \f$       | BinaryClassificationAccuracy, AveragePrecision
Multiclass classification   | Pointwise  | \f$ score \in \{c_1,c_2, \cdots, c_n\} \f$ | Accuracy
Regression                  | Pointwise  | \f$ score \in \mathbb{R} \f$               | AbsError, SquaredError, TruePoint
Ranking                     | {Point, Pair, List}wise |  sort by \f$ score \f$ | \link ltr::BaseDCG BaseDCG \endlink, \link ltr::BaseNDCG BaseNDCG \endlink, \link ltr::GMRR GMRR \endlink, PFound, ReciprocalRank

\section Learner Learner

Learner public fuctions:
 - \link Learner::learn learn  \endlink - learn the train data
 - \link Learner::make make \endlink, \link BaseLearner::makeSpecific makeSpecific \endlink   - return the pointer to a new scorer, see the example below to understand the difference
 - \link BaseLearner::setInitialScorer setInitialScorer \endlink - set the initial approximation of a scorer
 - \link BaseLearner::reset reset \endlink - reset a current state of the learner
 - \link Learner::GET_SET_VECTOR_OF_PTR(DataPreprocessor< TElement >, data_preprocessor)
   set_data_preprocessor \endlink - add data preprocessor, see \ref TutorialDataPreprocessors
 - \link Learner::GET_SET_VECTOR_OF_PTR(FeatureConverterLearner< TElement >, feature_converter_learner)
   set_feature_converter_learner \endlink - add feature converter learner, see \ref TutorialFeatureConverters

\section Scorer Scorer

Scorer public fuctions:
 - \link Scorer::value value \endlink - compute the score of an object
 - \link Scorer::predict predict \endlink - set predicted labels for all objects in a data set
 - \link Scorer::generateCppCode generateCppCode \endlink - serialize scorer to c++ code 

%Leaner Name:                 | Description:                     | Trained scorer:
------------------------------|----------------------------------|----------------------
BestFeatureLearner            |  one feature used as score | OneFeatureScorer
LinearLearner                 |  http://en.wikipedia.org/wiki/Ordinary_least_squares | LinearScorer
NNLearner                     |  http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm | NNScorer
gp::GPLearner                   |  http://en.wikipedia.org/wiki/Genetic_programming | gp::GPScorer
composition::CompositionLearner |  \ref TutorialComposition | composition::CompositionScorer
BayesianLearner  |  \ref TutorialBayesianClassification | BayesianScorer
decision_tree::DecisionTreeLearner | \ref TutorialDecisionTree  | decision_tree::DecisionTreeScorer
\section Measure Measure

Measure public fuctions:
 - \link Measure::operator()(const TElement &element)const operator() \endlink - compute how well predicted labels aproximates actual

%Measure Name:                | Description:
------------------------------|--------------------------------------
AbsError                      |http://en.wikipedia.org/wiki/Mean_absolute_error
Accuracy                      |http://en.wikipedia.org/wiki/Accuracy_and_precision
AveragePrecision              |http://en.wikipedia.org/wiki/Accuracy_and_precision
BinaryClassificationAccuracy  |http://en.wikipedia.org/wiki/Accuracy_and_precision
\link ltr::BaseDCG BaseDCG \endlink   |http://en.wikipedia.org/wiki/Discounted_Cumulative_Gain
\link ltr::BaseNDCG BaseNDCG \endlink |http://en.wikipedia.org/wiki/NDCG
\link ltr::GMRR GMRR \endlink |Desc
PFound                        |http://romip.ru/romip2009/15_yandex.pdf
ReciprocalRank                |http://en.wikipedia.org/wiki/Mean_reciprocal_rank
SquaredError                  |http://en.wikipedia.org/wiki/Squared_error_loss
TruePoint                     |Desc

\section Example Example

Example: Operating with learners and scorers     | Output:
-------------------------------------------------|------------------
\include tutorial_mls_example1.cpp               | \include tutorial_mls_example1.out

**/
}
