<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>Learning To Rank Library: Tutorial page 2 - Testing of algorithms</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />

<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script src="http://www.mathjax.org/mathjax/MathJax.js"></script>

</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">Learning To Rank Library
   
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.8.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div>
<div class="header">
  <div class="headertitle">
<div class="title">Tutorial page 2 - Testing of algorithms </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#CrossvalidationDataTest">Testing</a></li>
<li class="level1"><a href="#CrossvalidationDataTestCrossvalidation">Cross-validation</a><ul><li class="level2"><a href="#CrossvalidationDataTestCrossvalidationKFold">K-fold cross-validation</a></li>
<li class="level2"><a href="#CrossvalidationDataTestCrossvalidationTKFold">TK-fold cross-validation</a></li>
<li class="level2"><a href="#CrossvalidationDataTestCrossvalidationLeaveOneOut">Leave One Out cross-validation</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h2><a class="anchor" id="CrossvalidationDataTest"></a>
Testing</h2>
<p>There are two approaches in the testing of algorithms. First approach needs two datasets. The first dataset is training and the second is testing. Algorithm is learnt with the first dataset. And after the learning the algorithm is ought to be tested with the second dataset. But this approach needs a lot of data and usually there is a small amount of available data. So in machine learning more often used second approach that called cross-validation. Cross-validation is a technique for assessing how the results of a statistical analysis will generalize to an independent data set. One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.</p>
<h2><a class="anchor" id="CrossvalidationDataTestCrossvalidation"></a>
Cross-validation</h2>
<p>LTR library supports cross-validaion technique that was described in the beginning of this page.</p>
<p>CrossValidator is the class that performs crossvalidation over the selected data sets, learners, measures and splitters. It contains data:</p>
<ul>
<li>data_sets - data sets to run crossvalidation on </li>
<li>measures - measures, wich values will be calculated for every split </li>
<li>learners - learners used to produce scorers on train data </li>
<li>splitters - splitters used to split dataset into train + test sets</li>
</ul>
<p>CrossValidator contains following methods:</p>
<ul>
<li>addDataSet(const DataSet&lt;ObjectType&gt;&amp; data_set) - adds data_set to the crossvalidator </li>
<li>addLearner(const Learner&lt;ObjectType&gt;::Ptr&amp; learner_ptr) - adds learner_ptr shared pointer (!!) to the crossvalidator </li>
<li>addSplitter(const Splitter&lt;ObjectType&gt;::Ptr&amp; splitter_ptr) - adds splitter_ptr shared pointer (!!) to the crossvalidator </li>
<li>addMeasure(const Measure::Ptr&amp; measure_ptr) - adds measure_ptr shared pointer (!!) to the crossvalidator </li>
<li>launch() - launches crossvalidation process </li>
<li>toString() - converts crossvalidator to the printable string and forms set of tables </li>
<li>reset() - resets all the information in CrossVlidator</li>
</ul>
<p>To perform cross-validation, add to CrossValidator instance necessary datasets, learners. Add also different measures with the help of which you'll measure the quality of ranging and add splitters to specify a cross-validation type. Note that it is important to add exactly the shared_ptr to CrossValidator. Otherwise you can obtain strange and unstable behavior. Note that to use launch() you've got to have at least one implementation of datasets, launchers, splitters and measures.</p>
<p><br/>
 There are 3 different splitters implemented in LTR:</p>
<p>Splitters: <br/>
 </p>
<table class="doxtable">
<tr>
<th>Splitter: </th><th>Description:</th></tr>
<tr>
<td>K-fold cross-validation </td><td>In k-fold cross-validation, the original sample is randomly partitioned into k subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k - 1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds then can be averaged (or otherwise combined) to produce a single estimation. The advantage of this method over repeated random sub-sampling is that all observations are used for both training and validation, and each observation is used for validation exactly once. </td></tr>
<tr>
<td>TK-fold cross-validation </td><td>TK-fold cross-validation is an approach similar to K-fold cross-validation. The only difference between K-fold and TK-fold that TK-fold repeats K-fold cross-validation procedure T times with the random subsets. </td></tr>
<tr>
<td>Leave One Out cross-validation</td><td>As the name suggests, leave-one-out cross-validation involves using a single observation from the original sample as the validation data, and the remaining observations as the training data. This is repeated such that each observation in the sample is used once as the validation data. This is the same as a K-fold cross-validation with K being equal to the number of observations in the original sample. Leave-one-out cross-validation is computationally expensive because it requires many repetitions of training. </td></tr>
</table>
<p>Measures: <br/>
 </p>
<table class="doxtable">
<tr>
<th><a class="el" href="classltr_1_1_measure.html">Measure</a> Name: </th><th>Description:</th></tr>
<tr>
<td><a class="el" href="classltr_1_1_abs_error.html">AbsError</a> </td><td><a href="http://en.wikipedia.org/wiki/Mean_absolute_error">http://en.wikipedia.org/wiki/Mean_absolute_error</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_accuracy.html">Accuracy</a> </td><td><a href="http://en.wikipedia.org/wiki/Accuracy_and_precision">http://en.wikipedia.org/wiki/Accuracy_and_precision</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_average_precision.html">AveragePrecision</a> </td><td><a href="http://en.wikipedia.org/wiki/Accuracy_and_precision">http://en.wikipedia.org/wiki/Accuracy_and_precision</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_binary_classification_accuracy.html">BinaryClassificationAccuracy</a> </td><td><a href="http://en.wikipedia.org/wiki/Accuracy_and_precision">http://en.wikipedia.org/wiki/Accuracy_and_precision</a> </td></tr>
<tr>
<td>DCG </td><td><a href="http://en.wikipedia.org/wiki/Discounted_Cumulative_Gain">http://en.wikipedia.org/wiki/Discounted_Cumulative_Gain</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_g_m_r_r.html">GMRR</a> </td><td>Desc </td></tr>
<tr>
<td>NDCG </td><td><a href="http://en.wikipedia.org/wiki/NDCG">http://en.wikipedia.org/wiki/NDCG</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_normalized_measure.html">NormalizedMeasure</a> </td><td>Desc </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_p_found.html">PFound</a> </td><td><a href="http://romip.ru/romip2009/15_yandex.pdf">http://romip.ru/romip2009/15_yandex.pdf</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_reciprocal_rank.html">ReciprocalRank</a> </td><td><a href="http://en.wikipedia.org/wiki/Mean_reciprocal_rank">http://en.wikipedia.org/wiki/Mean_reciprocal_rank</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_squared_error.html">SquaredError</a> </td><td><a href="http://en.wikipedia.org/wiki/Squared_error_loss">http://en.wikipedia.org/wiki/Squared_error_loss</a> </td></tr>
<tr>
<td><a class="el" href="classltr_1_1_true_point.html">TruePoint</a> </td><td>Desc </td></tr>
</table>
<h3><a class="anchor" id="CrossvalidationDataTestCrossvalidationKFold"></a>
K-fold cross-validation</h3>
<p>In k-fold cross-validation, the original sample is randomly partitioned into k subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k - 1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds then can be averaged (or otherwise combined) to produce a single estimation. The advantage of this method over repeated random sub-sampling is that all observations are used for both training and validation, and each observation is used for validation exactly once.</p>
<h3><a class="anchor" id="CrossvalidationDataTestCrossvalidationTKFold"></a>
TK-fold cross-validation</h3>
<p>TK-fold cross-validation is an approach similar to K-fold cross-validation. The only difference between K-fold and TK-fold that TK-fold repeats K-fold cross-validation procedure T times with the random subsets.</p>
<h3><a class="anchor" id="CrossvalidationDataTestCrossvalidationLeaveOneOut"></a>
Leave One Out cross-validation</h3>
<p>As the name suggests, leave-one-out cross-validation involves using a single observation from the original sample as the validation data, and the remaining observations as the training data. This is repeated such that each observation in the sample is used once as the validation data. This is the same as a K-fold cross-validation with K being equal to the number of observations in the original sample. Leave-one-out cross-validation is computationally expensive because it requires many repetitions of training.</p>
<p>Here is an example how to use CrossValidator: </p>
<table class="doxtable">
<tr>
<th>Code: </th><th>Output:</th></tr>
<tr>
<td><div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;iostream&gt;</span>
<span class="preprocessor">#include &lt;vector&gt;</span>

<span class="preprocessor">#include &quot;boost/filesystem/path.hpp&quot;</span>

<span class="preprocessor">#include &quot;fstream&quot;</span>

<span class="preprocessor">#include &quot;<a class="code" href="crossvalidation_8h.html">ltr/crossvalidation/crossvalidation.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="leave__one__out__splitter_8h.html">ltr/crossvalidation/leave_one_out_splitter.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="validation__result_8h.html">ltr/crossvalidation/validation_result.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="object_8h.html">ltr/data/object.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="feature__info_8h.html">ltr/data/feature_info.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="best__feature__learner_8h.html">ltr/learners/best_feature_learner/best_feature_learner.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="abs__error_8h.html">ltr/measures/abs_error.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="measure_8h.html">ltr/measures/measure.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="fake__scorer_8h.html">ltr/scorers/fake_scorer.h</a>&quot;</span>

<span class="preprocessor">#include &lt;iostream&gt;</span>
<span class="preprocessor">#include &lt;algorithm&gt;</span>
<span class="preprocessor">#include &quot;<a class="code" href="object__list_8h.html">ltr/data/object_list.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="data__set_8h.html">ltr/data/data_set.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="io__utility_8h.html">ltr/data/utility/io_utility.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="dcg_8h.html">ltr/measures/dcg.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="ndcg_8h.html">ltr/measures/ndcg.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="best__feature__learner_8h.html">ltr/learners/best_feature_learner/best_feature_learner.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="linear__learner_8h.html">ltr/learners/linear_learner/linear_learner.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="nearest__neighbor__learner_8h.html">ltr/learners/nearest_neighbor_learner/nearest_neighbor_learner.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="gp__learner_8h.html">ltr/learners/gp_learner/gp_learner.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="nan__to__zero__learner_8h.html">ltr/feature_converters/nan_to_zero_learner.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="leave__one__out__splitter_8h.html">ltr/crossvalidation/leave_one_out_splitter.h</a>&quot;</span>
<span class="preprocessor">#include &quot;<a class="code" href="crossvalidator_8h.html">ltr/crossvalidation/crossvalidator.h</a>&quot;</span>

<span class="keyword">using</span> std::cout;
<span class="keyword">using</span> std::vector;
<span class="keyword">using</span> std::endl;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_object_list.html">ltr::ObjectList</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_data_set.html">ltr::DataSet</a>;
<span class="keyword">using</span> ltr::io_utility::loadDataSet;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_measure.html">ltr::Measure</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_base_d_c_g.html">ltr::DCG</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_base_n_d_c_g.html">ltr::NDCG</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_best_feature_learner.html">ltr::BestFeatureLearner</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_feature_converter.html" title="A base class for feature converters.">ltr::FeatureConverter</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_nan_to_zero_converter_learner.html">ltr::NanToZeroConverterLearner</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1cv_1_1_leave_one_out_splitter.html">ltr::cv::LeaveOneOutSplitter</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1cv_1_1_cross_validator.html">ltr::cv::CrossValidator</a>;
<span class="keyword">using</span> ltr::Log;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_linear_learner.html">ltr::LinearLearner</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1_n_n_learner.html" title="NNLearner Implements nearest neighbor approach.">ltr::NNLearner</a>;
<span class="keyword">using</span> <a class="code" href="classltr_1_1gp_1_1_g_p_learner.html" title="GPLearner Implements genetic programming approach applied to learning to rank.">ltr::gp::GPLearner</a>;

<span class="keyword">using</span> std::fstream;

<span class="keywordtype">int</span> <a class="code" href="generator_8cc.html#a0ddf1224851353fc92bfbff6f499fa97">main</a>() {
  Log log(<span class="stringliteral">&quot;log.txt&quot;</span>);
  DataSet&lt;ObjectList&gt; test_data = loadDataSet&lt;ObjectList&gt;(
          <span class="stringliteral">&quot;data/imat2009/imat2009_test_small.txt&quot;</span>, <span class="stringliteral">&quot;Yandex&quot;</span>);
  DataSet&lt;ObjectList&gt; train_data = loadDataSet&lt;ObjectList&gt;(
          <span class="stringliteral">&quot;data/imat2009/imat2009_learning_small.txt&quot;</span>, <span class="stringliteral">&quot;Yandex&quot;</span>);

  NanToZeroConverterLearner&lt;ObjectList&gt; converter;
  converter.learn(train_data);
  <a class="code" href="classltr_1_1_feature_converter.html#ac7e70cea2b5abeb4011ae543afe871cd">FeatureConverter::Ptr</a> remove_nan = converter.make();

  remove_nan-&gt;apply(train_data, &amp;train_data);
  remove_nan-&gt;apply(test_data, &amp;test_data);

  Measure&lt;ObjectList&gt;::Ptr measure_one(<span class="keyword">new</span> DCG());
  Measure&lt;ObjectList&gt;::Ptr measure_two(<span class="keyword">new</span> NDCG());
  BestFeatureLearner&lt;ObjectList&gt;::Ptr learner_one =
      <span class="keyword">new</span> BestFeatureLearner&lt;ObjectList&gt;(measure_one);
  learner_one-&gt;learn(train_data);

  GPLearner&lt;ObjectList&gt;::Ptr learner_two =
      <span class="keyword">new</span> GPLearner&lt;ObjectList&gt;(measure_one);
  learner_two-&gt;learn(train_data);

  LeaveOneOutSplitter&lt;ObjectList&gt;::Ptr splitter=
      <span class="keyword">new</span> LeaveOneOutSplitter&lt;ObjectList&gt;();

  CrossValidator&lt;ObjectList&gt; cross_validator;
  cross_validator.addDataSet(train_data);
  cross_validator.addLearner(learner_one);
  cross_validator.addLearner(learner_two);
  cross_validator.addMeasure(measure_one);
  cross_validator.addMeasure(measure_two);
  cross_validator.addSplitter(splitter);
  cross_validator.launch();
  cout &lt;&lt; cross_validator.toString();

  <span class="keywordflow">return</span> 0;
}
</pre></div></td><td><div class="fragment"><pre class="fragment">
DataSet:DataSet
Splitter:LeaveOneOutSplitter
Table ROW: Measure COLUMN: Learner
        BestFeatureLeaner       GPLeaner        
DCG     2.319   2.069   
NDCG    1       0.75    
</pre></div> </td></tr>
</table>
</div></div><!-- contents -->


<hr class="footer"/><address class="footer"><small>
Generated on Tue Oct 16 2012 12:30:03 for Learning To Rank Library by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.0
</small></address>

</body>
</html>
