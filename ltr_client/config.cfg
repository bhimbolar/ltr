<LTR_experiment>
  <config>
    <root_directory>.</root_directory>
  </config>

  <data name="learn" approach="listwise" format="Yandex">data/imat2009/imat2009_learning.txt</data>
  <data name="test" approach="listwise" format="Yandex">data/imat2009/imat2009_test.txt</data>

  <learner name="NN1" type="NNLearner" approach="listwise">
    <metric>EUCLIDEAN_METRIC</metric>
    <neighbor_weighter>INVERSE_LINEAR_DISTANCE</neighbor_weighter>
    <predictions_aggregator>AVERAGE_AGGREGATOR</predictions_aggregator>
    <number_of_neighbors_to_process>2</number_of_neighbors_to_process>
  </learner>

  <learner name="NN2" type="NNLearner" approach="listwise">
    <metric>MANHATTAN_METRIC</metric>
    <neighbor_weighter>INVERSE_POWER_DISTANCE</neighbor_weighter>
    <predictions_aggregator>SUM_AGGREGATOR</predictions_aggregator>
    <number_of_neighbors_to_process>2</number_of_neighbors_to_process>
  </learner>

  <learner name="NN3" type="NNLearner" approach="listwise">
    <metric>MANHATTAN_METRIC</metric>
    <neighbor_weighter>INVERSE_ORDER</neighbor_weighter>
    <predictions_aggregator>VOTE_AGGREGATOR</predictions_aggregator>
    <number_of_neighbors_to_process>3</number_of_neighbors_to_process>
  </learner>

  <learner name="BF1" type="BestFeatureLearner" approach="listwise">
    <measure>dcg</measure>
  </learner>

  <learner name="BF2" type="BestFeatureLearner" approach="listwise">
    <measure>ndcg</measure>
  </learner>

  <learner name="GP" type="GPLearner" approach="listwise">
    <POPULATION_SIZE>10</POPULATION_SIZE>
    <NUMBER_OF_GENERATIONS>3</NUMBER_OF_GENERATIONS>
    <MIN_INIT_DEPTH>2</MIN_INIT_DEPTH>
    <MAX_INIT_DEPTH>5</MAX_INIT_DEPTH>
    <INIT_GROW_PROBABILITY>0.5</INIT_GROW_PROBABILITY>
    <SEED>1</SEED>
  </learner>

  <learner name="FISHER_LDA" type="FisherDiscriminantLearner" approach="listwise">
  </learner>

  <learner name="QDA" type="QuadraticDiscriminantLearner" approach="listwise">
  </learner>

  <learner name="NAIVE_BAYES" type="NormalNaiveBayesLearner" approach="listwise">
  </learner>

  <measure name="dcg" type="DCG">
    <NUMBER_OF_OBJECTS_TO_CONSIDER>3</NUMBER_OF_OBJECTS_TO_CONSIDER>
  </measure>

  <measure name="dcg2" type="DCG">
    <NUMBER_OF_OBJECTS_TO_CONSIDER>2</NUMBER_OF_OBJECTS_TO_CONSIDER>
  </measure>

  <measure name="dcg3" type="DCG">
    <NUMBER_OF_OBJECTS_TO_CONSIDER>3</NUMBER_OF_OBJECTS_TO_CONSIDER>
  </measure>

  <measure name="ndcg" type="NDCG">
    <NUMBER_OF_OBJECTS_TO_CONSIDER>2</NUMBER_OF_OBJECTS_TO_CONSIDER>
  </measure>

  <splitter name="K_FOLD1" type="KFoldSimpleSplitter" approach="listwise">
      <K>2</K>
  </splitter>

  <metric name="EUCLIDEAN_METRIC" type="EuclideanMetric">
  </metric>

  <metric name="MANHATTAN_METRIC" type="ManhattanMetric">
  </metric>

  <predictions_aggregator name="AVERAGE_AGGREGATOR" type="AveragePredictionsAggregator">
  </predictions_aggregator>

  <predictions_aggregator name="SUM_AGGREGATOR" type="SumPredictionsAggregator">
  </predictions_aggregator>

  <predictions_aggregator name="VOTE_AGGREGATOR" type="VotePredictionsAggregator">
  </predictions_aggregator>

  <neighbor_weighter name="INVERSE_LINEAR_DISTANCE" type="InverseLinearDistance">
  </neighbor_weighter>

  <neighbor_weighter name="INVERSE_POWER_DISTANCE" type="InversePowerDistance">
  </neighbor_weighter>

  <neighbor_weighter name="INVERSE_ORDER" type="InverseOrder">
  </neighbor_weighter>

  <launch>
    <train name="test1" data="learn" learner="BF2">
      <predict>test</predict>
      <cpp/>
    </train>
    <crossvalidation fold="K_FOLD1">
      <learner>BF1</learner>
      <learner>BF2</learner>
      <learner>NN1</learner>
      <learner>NN2</learner>
      <learner>NN3</learner>
      <learner>FISHER_LDA</learner>
      <learner>QDA</learner>
      <learner>NAIVE_BAYES</learner>

      <measure>dcg</measure>
      <measure>dcg2</measure>
      <measure>dcg3</measure>
      <measure>ndcg</measure>

      <data>learn</data>

    </crossvalidation>
  </launch>

</LTR_experiment>
